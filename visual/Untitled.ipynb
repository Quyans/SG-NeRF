{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1106b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "\n",
    "fileadd = \"./0_net_ray_marching.pth\"\n",
    "bpnetadd=\"./1_semanticEmbedding.pth\"\n",
    "\n",
    "# 矩阵最大值最小值\n",
    "def maxMat(mat):\n",
    "    maxarr = []\n",
    "    for i in range(len(mat)):\n",
    "#         print(mat[i])\n",
    "        maxarr.append(max(mat[i])) \n",
    "    return max(maxarr)\n",
    "\n",
    "def minMat(mat):\n",
    "    minarr = []\n",
    "    for i in range(len(mat)):\n",
    "        minarr.append(min(mat[i])) \n",
    "    return min(minarr)\n",
    "\n",
    "def normalization(data):\n",
    "    _range = max(data) - min(data)\n",
    "    return (data - min(data)) / _range\n",
    "\n",
    "# 采用方案二\n",
    "def float2color(zero2one):\n",
    "    x = zero2one * 256 * 256 * 256\n",
    "    r = x % 256\n",
    "    g = ((x - r)/256 % 256)\n",
    "    b = ((x - r - g * 256)/(256*256) % 256)\n",
    "    r = round(float(r),2)\n",
    "    g = round(float(g),2)\n",
    "    b = round(float(b),2)\n",
    "    return (r,g,b)\n",
    "\n",
    "def fixcolor(data):\n",
    "\n",
    "    return (data,200,150)\n",
    "\n",
    "def hsv2rgb(h, s, v):\n",
    "    h = float(h)\n",
    "    s = float(s)\n",
    "    v = float(v)\n",
    "    h60 = h / 60.0\n",
    "    h60f = math.floor(h60)\n",
    "    hi = int(h60f) % 6\n",
    "    f = h60 - h60f\n",
    "    p = v * (1 - s)\n",
    "    q = v * (1 - f * s)\n",
    "    t = v * (1 - (1 - f) * s)\n",
    "    r, g, b = 0, 0, 0\n",
    "    if hi == 0: r, g, b = v, t, p\n",
    "    elif hi == 1: r, g, b = q, v, p\n",
    "    elif hi == 2: r, g, b = p, v, t\n",
    "    elif hi == 3: r, g, b = p, q, v\n",
    "    elif hi == 4: r, g, b = t, p, v\n",
    "    elif hi == 5: r, g, b = v, p, q\n",
    "    r, g, b = int(r * 255), int(g * 255), int(b * 255)\n",
    "    return [r, g, b]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "0e267180",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20550, 3])\n",
      "torch.Size([20550, 32])\n"
     ]
    }
   ],
   "source": [
    "data = torch.load(fileadd)\n",
    "data[\"neural_points.points_embeding\"].shape\n",
    "# max(a[\"neural_points.points_embeding\"])\n",
    "# min(a[\"neural_points.points_embeding\"])\n",
    "\n",
    "embedding = data[\"neural_points.points_embeding\"][0]\n",
    "# embedding\n",
    "# maxnum = maxMat(embedding[0])\n",
    "# minnum = minMat(embedding[0])\n",
    "xyz = data[\"neural_points.xyz\"]\n",
    "print(xyz.shape)\n",
    "print(embedding.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "401a5a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.1833e-02,  6.5631e-01,  9.5582e-01,  ..., -3.3950e-03,\n",
      "          1.1371e+00,  5.0413e-02],\n",
      "        [-6.2445e-04,  5.7674e-01,  1.1763e+00,  ..., -3.1546e-03,\n",
      "          1.5957e+00,  2.9253e-02],\n",
      "        [ 1.1702e-01,  4.0329e-01,  7.6346e-01,  ..., -1.1105e-03,\n",
      "          6.4104e-01, -2.3781e-04],\n",
      "        ...,\n",
      "        [-7.6880e-04,  9.9284e-01,  7.2517e-01,  ...,  3.7296e-02,\n",
      "          2.9070e-01, -5.5827e-03],\n",
      "        [ 1.4753e-02,  8.1437e-01,  8.2889e-01,  ...,  8.9745e-02,\n",
      "          1.9489e-01, -6.1652e-03],\n",
      "        [-1.2548e-03, -1.0420e-03,  4.4593e-01,  ..., -4.6876e-03,\n",
      "          6.2164e-01,  5.4464e-03]])\n",
      "(32, 20550)\n",
      "(32, 20550)\n",
      "[[0.02116549 0.00561014 0.06199167 ... 0.00554096 0.01298006 0.00530804]\n",
      " [0.30470788 0.26821482 0.18866561 ... 0.4590437  0.3771946  0.00323022]\n",
      " [0.5413591  0.6648008  0.4336652  ... 0.41222608 0.47029328 0.25588772]\n",
      " ...\n",
      " [0.00317596 0.0033185  0.00453067 ... 0.02730664 0.05840977 0.00240938]\n",
      " [0.32502842 0.45510682 0.18431892 ... 0.08494545 0.05776718 0.17881845]\n",
      " [0.0824241  0.05604583 0.0192832  ... 0.01262033 0.01189417 0.02636907]]\n",
      "./pointfeature_colorful 创建成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vr717/anaconda3/envs/pointnerf11/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:236: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  \"Numerical issues were encountered \"\n",
      "/home/vr717/anaconda3/envs/pointnerf11/lib/python3.7/site-packages/sklearn/preprocessing/_data.py:255: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  \"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "# 对每一列归一化  对vgg网络可视化\n",
    "print(embedding)\n",
    "embedT = embedding.T.numpy()\n",
    "print(embedT.shape)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#线性归一化\n",
    "embedTnorm = []\n",
    "for i in range(len(embedT)):\n",
    "    tem = normalization(copy.deepcopy(embedT[i]))\n",
    "    embedTnorm.append(tem)\n",
    "#     print(min(a),max(a))\n",
    "#     print(a.shape)\n",
    "embedTnorm = np.array(embedTnorm)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# \"\"\"\n",
    "# zscore标准化\n",
    "embedTnorm = []\n",
    "for i in range(len(embedT)):\n",
    "    tem = normalization(copy.deepcopy(embedT[i]))\n",
    "#     tem = preprocessing.scale(embedT[i])*50+128\n",
    "    embedTnorm.append(tem)\n",
    "#     print(min(a),max(a))\n",
    "#     print(a.shape)\n",
    "embedTnorm = np.array(embedTnorm)\n",
    "# \"\"\"\n",
    "\n",
    "# embedTnorm = []\n",
    "# minmax = preprocessing.MinMaxScaler()\n",
    "# for i in range(len(embedT)):\n",
    "#     tem = minmax.fit_transform([embedT[i]])\n",
    "#     embedTnorm.append(tem)\n",
    "# #     print(min(a),max(a))\n",
    "# #     print(a.shape)\n",
    "# embedTnorm = np.array(embedTnorm)\n",
    "\n",
    "\n",
    "embed = preprocessing.scale(embedTnorm)\n",
    "\n",
    "print(embedTnorm.shape)\n",
    "print(embedTnorm)\n",
    "embed = embedTnorm.T\n",
    "\n",
    "basepath = \"./pointfeature_colorful\"\n",
    "isExists=os.path.exists(basepath)\n",
    "    # 判断结果\n",
    "if not isExists:\n",
    "    # 如果不存在则创建目录\n",
    "     # 创建目录操作函数\n",
    "    os.makedirs(basepath) \n",
    "    print(basepath+' 创建成功')\n",
    "\n",
    "\n",
    "for i in range(len(embed[0])):\n",
    "    mat = []\n",
    "    for j in range(len(embed)):\n",
    "        temrow = np.append(xyz[j],fixcolor(embed[j][i]))\n",
    "        mat.append(temrow)\n",
    "    \n",
    "    np.savetxt( os.path.join(basepath,\"pointFeature_color{}.txt\".format(str(i))), np.array(mat), fmt='%f', delimiter=',')\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "da10cdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20550, 3])\n",
      "(96, 20550)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "bpfeature = torch.load(bpnetadd)\n",
    "\n",
    "print(xyz.shape)\n",
    "\n",
    "embedT = bpfeature.T.numpy()\n",
    "print(embedT.shape)\n",
    "embedTnorm = []\n",
    "for i in range(len(embedT)):\n",
    "    tem = normalization(copy.deepcopy(embedT[i]))\n",
    "#     tem = preprocessing.scale(embedT[i])*70+128\n",
    "    embedTnorm.append(tem)\n",
    "#     print(min(a),max(a))\n",
    "#     print(a.shape)\n",
    "embedTnorm = np.array(embedTnorm)\n",
    "\n",
    "embed = embedTnorm.T\n",
    "\n",
    "\"\"\"\n",
    "float2color\n",
    "\"\"\"\n",
    "# for i in range(len(embed[0])):\n",
    "#     mat = []\n",
    "#     for j in range(len(embed)):\n",
    "#         temrow = np.append(xyz[j],float2color(embed[j][i]))\n",
    "#         mat.append(temrow)\n",
    "    \n",
    "#     np.savetxt('./bpnetfeature/pointFeatureHSV_{}.txt'.format(str(i)), np.array(mat), fmt='%f', delimiter=',')\n",
    "#     print(i)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "hsv2rgb\n",
    "\"\"\"\n",
    "# for i in range(len(embed[0])):\n",
    "#     mat = []\n",
    "#     for j in range(len(embed)):\n",
    "#         temrow = np.append(xyz[j],hsv2rgb(embed[j][i],1,1))\n",
    "#         mat.append(temrow)\n",
    "    \n",
    "#     np.savetxt('./bpnetfeature_hsv/pointFeatureHSV_{}.txt'.format(str(i)), np.array(mat), fmt='%f', delimiter=',')\n",
    "#     print(i)\n",
    "\n",
    "\n",
    "basepath = \"./bpnetfeature_colorful\"\n",
    "isExists=os.path.exists(basepath)\n",
    "    # 判断结果\n",
    "if not isExists:\n",
    "    # 如果不存在则创建目录\n",
    "     # 创建目录操作函数\n",
    "    os.makedirs(basepath) \n",
    "    print(basepath+' 创建成功')\n",
    "\n",
    "for i in range(len(embed[0])):\n",
    "    mat = []\n",
    "    for j in range(len(embed)):\n",
    "        temrow = np.append(xyz[j],float2color(embed[j][i]))\n",
    "        mat.append(temrow)\n",
    "    \n",
    "    np.savetxt(os.path.join(basepath,\"bpnet_{}.txt\".format(str(i))) , np.array(mat), fmt='%f', delimiter=',')\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
